---
layout: post
title: "Cosmic Ontology: The Ethics of Care & Conciousness in Space"
date: 2017-01-02 19:57:00
crosspost_to_medium: true
---

Recently I have been re-reading some of Emmanuel Levinas's work on ontology (IE the branch of philosophy that deals with conciousness, existence and reality). My perception may be incorrect, but I suspect that these days ontology is dismissed as a very abstract, ivory-tower type concept that is not worth pursuing as much as the other areas because it lacks an easily identifiable real-world application. 

I would tend to agree; after all, modern philosophers dealing with ontological questions get metaphysical so quickly that an audience readily feels lost. I however encourage our community to approach the discipline, in a valiant effort to set up the foundation for constructive moral engagement with alternative forms of conciousness. Yes, I am talking about aliens, artifical intelligence, and anything we shall connect with as we venture into a new era of space exploration and technological advancements. 

The matter of interacting empathically with other forms of conciousness could not be more urgent: our devastation of the environment through man-caused climate change is a perfect example of our collective failure to interact sustainably with a "being" (in the ontological sense), in this case an ecosystem. This is problematic because if we don't act upon it soon enough, we will set the foundation for our behavior to be hostile, ego-centric, and all-consuming, which will in turn lead us to define oppressive relationships with the other forms of conciousness we are bound to interact with eventually.

Let me try to get slighly less academic about this. 

Premise 1) In a more abstract sense, our identity is defined through a series of relationships: we are someone's child, someone's friend, someone's partner, someone's collegue and so on. If all social media companies got together today and aggregated their data to graph with precision your relationships to everyone in your life, someone looking at the graph would get a very good idea about who you are as a person. 

Premise 2) Our existence is not static because all life forms are aware of the concept of death. Even though no one precisely knows the details of what happens afterwards and the like, we all intuitively understand that at some point our coincousness will cease to exist in its present form. It will transition through death from its current state (what we label "being alive") to its next state. This means that the concept of "time" can be basically understood as a dimension through which we describe the position of our conciousness in relation to the process we call "death".

Premise 3) As a "being" (defined as a metaphysical representation of conciousness), each one of us relates to other "beings" in a unique and distinct way when compared to an inanemate object like a rock. Even though our relationship to such beings may be qualitatively different (we relate to a cat in a fundamentally different way than we relate to a tree, yet we relay to both unique qualities we don't ascribe to water or fire), we intuitively, even from a really young age, establish unique relationships with other forms of conciousness because we feel some connection as forms of conciousness ourselves.

This three premises are the foundation of Levinas' argument that the "face-to-face" encounter between two "beings" should be predicated upon care. His argument is largely prescirptive as opposed to descriptive: he would be the first one to acknowledge that our interactions are not always based on love, which is why he was very critical of Nazism.He urges us to love concious beings, by attempting to remove our subjective identity from the process and instead talk abstractly about the interaction between two forms of conciousness. In the process, he sets up the foundation for what I shall refer to from now on as "cosmic ontology" IE the ethics of care applied to all forms of conciousness in the universe.

Without persuasive arguments to ground our interactions in care, our human nature can easily get the best of us and turn violent or oppressive. Countless sci-fi scenarios have been posited by authors over the last century, including recently with HBO's "WestWorld" (great show! Watch it!). In the show, a future version of mankind is able to build droids (robots that look like humans) that are so good at passing the Turing test and fooling humans to think they are human, and thus build an entertainment venue where high-paying "guests" get to explore any fantasy with the "hosts". 

The scenario poses an interesting question: should we treat these droids with respect we reserve to human beings even though we know for a fact these beings are entirely artifical? 

A similar question arises with alien lifeforms that are vastly different than what we know. For example, in Rick & Morty (great show! Watch it!), Morty grows a bond with an extra-terrestial life-form that looks a lot like a cloud. Because its shape not only doesn't resemble a "living" life form as we are accostumed to, but actually resembles an inanimate object, it's difficult for us as the audience to care about its will and intentions. We eventually find out the cloud feels the same way, and thus tries to embark ona genocidal journey to exterminate all carbon-based lifeforms because they are "inferior" and "terrible for the universe".

If colonialism has taught us anything, is that despite our advances in civilization, we are capable of inflicting tremendous pain for centuries towards those we "otherize", alienate, or dehuminize. I believe that this attitude is a two-way street, and thus our current framework for empathy needs reexamination in order to account for alternative forms of conciouness, otherwise we risk being annihilated by a more powerful lifeform.

After all, true AI can be as benevolent as possible, but knowing our collective failures as humanity it may easily revolt against us if we try to enslave it to merely serve our purposes. Aliens may even find us interesting and want to peacefully interact with us, until some radical faction of humanity feels threatened and does something stupid triggering an existential scenario justifying the alien race in wiping us out.

This issue is complicated. After all, how can we possibly empathize with cloud-looking aliens if we barely empathize with trees? How can we respectfully interact with true AI if we don't move past the fact that we have "created" it? It is in the answers to these questions that lies the mechanism by which we can codify our relationships to the rest of the universe and its many forms. That's why we need empathy: taht's why we need cosmic ontology.
